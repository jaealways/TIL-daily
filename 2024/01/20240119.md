# TOC
- [CS](#cs)
  * [PS](#ps)
    + [931. Minimum Falling Path Sum](#931-minimum-falling-path-sum)
- [DEV](#dev)
  * [RE task](#re-task)
    + [7조 발표](#7----)
    + [4팀 발표](#4----)


# Goal

- [x] PS: 931. Minimum Falling Path Sum
- [x] PAPER: NewsEdits: A Dataset of News Article Revision Histories and a Novel Document-Level Reasoning Challenge	
- [ ] PAPER: tldr, CV list
- [x] PAPER: read nlp tldr



# CS
## PS
### 931. Minimum Falling Path Sum
- 시간복잡도를 줄이기 위해, dp를 사용
- 본질만 생각하기: 모든 경우의 수를 backtracking 할 필요 없음
- 현 시점에서 이미 이전에 주어진 최소값만 참고하면 됨 -> 이전 layer 정보만 저장하기


# DEV
## RE task
### 7조 발표
- 데이터 분석을 정말 자세하게 잘 함, 데이터 보완하는 작업
- hyperparameter tuning, ensemble
- 데이터 후처리 고민, subject type
- 모델 자체에 대한 튜닝이 들어갔으면 좀 더 좋았을 것
- backbone이 아니라 LSTM layer로 하거나
- 병렬처리 항목 들어가면 과제 점수 만점

- 한국어 모델로 공개된 데이터 여러가지 있음
- 똑같은 임베딩 모델 공개된거 많음, DeBERTa
- 뉴스 검색할 때는 [KPF-BERT](https://huggingface.co/jinmang2/kpfbert) 언론재단에서 만든 모델 선택
- Source에 맞는 모델 선택
- 이진분류를 앞에서 하면, 에러 전파되는 경우가 있어서 정확도가 오히려 낮아지는 경우 있음
- 파이프라인 자체를 줄여야 에러 전파를 줄일 수 있음
- 중요한게 validation 뽑았음, 실제 KLUE에서 이렇게 함
- Train에서 안보였던 것들 최대한 Test에 넣었음

### 4팀 발표
- 문제 정의를 넣어주어 대회 참가하지 않은 사람도 잘 파악할 수 있게 하기
- no_relation이 진짜 no_realation인가?
  - 많은 작업자가 귀찮아서 no_relation으로 라벨링하는 경우도 많음
- 데이터 증강한 것도 데이터 구축 경험에 도움됨
- 성능 향상에 실패한 경험에 대해 소개해준 것도 많음
  - 성능이 잘 안나오면 숨기고 싶은 마음, 내 기록으로 노하우가 되어 다시 실수 안할 수도...
- 데이터 증강할 때, 모델이 취약한 부분 위주로

- RE 태스크는 실제로 관계추출을 통해 채팅에서도 사용 가능
- 할루시네이션 해결하기 위해, Retrieval, Knowledge graph 사용
- 기업 평가 기준 항목표 내용: 케바케
  - 데이터셋에 대한 분석을 자세히 했는가?
  - 문제 정의를 정확히 이해했는가?
  - 문제 정의가 명확히 되면 모델링이 자연히 따라 붙음
  - 데이터 증강할 때, bert는 이미 mask했기 때문에, mask하는건 크게 의미 없는 것 같다
- 베이스라인을 가장 못하는 모델로 잡으면, 발전 가능성 많음
- 모델을 학습시킬 떈, 문제를 어렵게 만들어야 함.
  - 사람이 봤을 때 긴가민가한걸 넣어주는게 좋음

