# TOC
- [DEV](#dev)
  * [LSTM](#lstm)
  * [prompt augmentation](#prompt-augmentation)


# Goal

- [x] PS: 1657. Determine if Two Strings Are Close
- [x] PAPER: Probing via Prompting and Pruning	
- [ ] DEV: pytorch lightning loss function by task
- [ ] DEV: make module of LDAM loss, 
- [x] DEV: make module of converting pdf to text


# DEV

## LSTM
- 파이토치 내에 블록 따로 있음
- 원래 LSTM 쓰는대신 multi head-attention 사용
- long-term dependency
- head 대신??
- https://github.com/boostcampaitech3/level2-klue-level2-nlp-10/blob/master/code/train.py


## prompt augmentation
- model weakness를 중심으로 증강하고 싶음
    - subject와 obj 사이의 관계를 보존해서 증강하는게 좋을 것 같은데 어떤 점들을 추가 고려해야 하는가?
- 사실 기존 데이터로 증강하는 건 쉽지 않음
- 위키에서 긁어와서 sbj, obj 태깅하라고 하는게 좀 더 좋은 접근
- 프롬프트 실험 관련한 페이퍼 잘 없음
  - 오히려 트위터 찾아보는게 좋을 수도
- RE 데이터 증상이 엄청 연구 주제는 아님
- 프롬프트 판매하는 사이트 찾아보는 것도 좋을 수 있음
  - 오히려 트위터에 있는 글들이 논문보다 더 좋은 impact factor 가질 수 있음
